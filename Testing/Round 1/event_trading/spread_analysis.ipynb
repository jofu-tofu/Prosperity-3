{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spread Analysis for Event-Based Trading\n",
    "\n",
    "This notebook focuses on analyzing bid-ask spread events for Squid_Ink. We'll use only the first 20,000 timestamps (in-sample data) for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Import our backtester package\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from backtester import get_price_data, get_vwap, relative_entropy_binned\n",
    "print(\"Using backtester package\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "First, let's load the Squid_Ink price data and limit it to the first 20,000 timestamps (in-sample data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data directly using backtester package\n",
    "print(\"Loading price data...\")\n",
    "prices = get_price_data('SQUID_INK', 1)\n",
    "print(f\"Loaded {len(prices)} price data points\")\n",
    "\n",
    "# Limit to first 20,000 timestamps (in-sample data)\n",
    "in_sample_prices = prices.iloc[:20000]\n",
    "print(f\"Limited to {len(in_sample_prices)} in-sample data points\")\n",
    "\n",
    "# Get VWAP\n",
    "print(\"Getting VWAP for SQUID_INK...\")\n",
    "squid_vwap = in_sample_prices['vwap']\n",
    "print(f\"Got VWAP with {len(squid_vwap)} data points\")\n",
    "print(f\"VWAP range: {squid_vwap.min()} to {squid_vwap.max()}\")\n",
    "\n",
    "# Calculate log returns\n",
    "log_ret = np.log(squid_vwap).diff().dropna()\n",
    "print(f\"Calculated log returns with {len(log_ret)} data points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Spread Metrics\n",
    "\n",
    "Let's calculate bid-ask spread metrics from the order book data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bid-ask spread\n",
    "in_sample_prices['spread'] = in_sample_prices['ask_price_1'] - in_sample_prices['bid_price_1']\n",
    "\n",
    "# Calculate relative spread (spread as a percentage of mid price)\n",
    "in_sample_prices['mid_price'] = (in_sample_prices['ask_price_1'] + in_sample_prices['bid_price_1']) / 2\n",
    "in_sample_prices['relative_spread'] = in_sample_prices['spread'] / in_sample_prices['mid_price'] * 100  # in percentage\n",
    "\n",
    "# Calculate spread moving average and volatility\n",
    "window = 50  # 50-period window\n",
    "in_sample_prices['spread_ma'] = in_sample_prices['spread'].rolling(window=window).mean()\n",
    "in_sample_prices['spread_std'] = in_sample_prices['spread'].rolling(window=window).std()\n",
    "\n",
    "# Calculate z-score of spread\n",
    "in_sample_prices['spread_zscore'] = (in_sample_prices['spread'] - in_sample_prices['spread_ma']) / in_sample_prices['spread_std']\n",
    "\n",
    "# Display the first few rows\n",
    "in_sample_prices[['spread', 'relative_spread', 'spread_ma', 'spread_std', 'spread_zscore']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize Spread Metrics\n",
    "\n",
    "Let's visualize the spread metrics over time and their distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spread metrics over time\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Plot absolute spread\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(in_sample_prices['spread'], label='Spread')\n",
    "plt.plot(in_sample_prices['spread_ma'], label='Spread MA', color='red')\n",
    "plt.title('Absolute Spread Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot relative spread\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(in_sample_prices['relative_spread'], label='Relative Spread (%)')\n",
    "plt.title('Relative Spread Over Time (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot spread z-score\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(in_sample_prices['spread_zscore'], label='Spread Z-Score')\n",
    "plt.axhline(y=2, color='red', linestyle='--', label='Z=2')\n",
    "plt.axhline(y=-2, color='red', linestyle='--', label='Z=-2')\n",
    "plt.title('Spread Z-Score Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot spread distributions\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot absolute spread distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(in_sample_prices['spread'].dropna(), bins=50)\n",
    "plt.title('Absolute Spread Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot relative spread distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(in_sample_prices['relative_spread'].dropna(), bins=50)\n",
    "plt.title('Relative Spread Distribution (%)')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot spread z-score distribution\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.hist(in_sample_prices['spread_zscore'].dropna(), bins=50)\n",
    "plt.title('Spread Z-Score Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot spread vs. VWAP\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(in_sample_prices['vwap'], in_sample_prices['spread'], alpha=0.5)\n",
    "plt.title('Spread vs. VWAP')\n",
    "plt.xlabel('VWAP')\n",
    "plt.ylabel('Spread')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Spread Events\n",
    "\n",
    "Let's define spread events based on extreme values of the spread z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds for spread events\n",
    "spread_thresholds = {\n",
    "    'moderate': 1.5,  # 1.5 standard deviations\n",
    "    'strong': 2.0,    # 2.0 standard deviations\n",
    "    'extreme': 2.5    # 2.5 standard deviations\n",
    "}\n",
    "\n",
    "# Display the thresholds\n",
    "for name, threshold in spread_thresholds.items():\n",
    "    print(f\"{name.capitalize()} spread threshold: {threshold:.1f} standard deviations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify spread events\n",
    "spread_events = pd.DataFrame(index=in_sample_prices.index)\n",
    "spread_events['spread'] = in_sample_prices['spread']\n",
    "spread_events['spread_zscore'] = in_sample_prices['spread_zscore']\n",
    "\n",
    "# Classify spread events by magnitude\n",
    "for name, threshold in spread_thresholds.items():\n",
    "    # Widening spread (positive z-score)\n",
    "    spread_events[f'{name}_widening'] = (spread_events['spread_zscore'] > threshold).astype(int)\n",
    "    \n",
    "    # Narrowing spread (negative z-score)\n",
    "    spread_events[f'{name}_narrowing'] = (spread_events['spread_zscore'] < -threshold).astype(int)\n",
    "\n",
    "# Display the first few rows\n",
    "spread_events.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Spread Events\n",
    "\n",
    "Let's analyze the frequency and characteristics of spread events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of spread events by type\n",
    "spread_counts = {}\n",
    "\n",
    "for col in spread_events.columns:\n",
    "    if col.endswith('_widening') or col.endswith('_narrowing'):\n",
    "        spread_counts[col] = spread_events[col].sum()\n",
    "\n",
    "# Calculate the percentage of spread events\n",
    "total_points = len(spread_events)\n",
    "spread_percentages = {k: v / total_points * 100 for k, v in spread_counts.items()}\n",
    "\n",
    "# Display the counts and percentages\n",
    "counts_df = pd.DataFrame({\n",
    "    'Count': spread_counts,\n",
    "    'Percentage (%)': spread_percentages\n",
    "})\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Spread Events\n",
    "\n",
    "Let's visualize the spread events on the VWAP chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VWAP with spread events\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot VWAP\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(squid_vwap, label='VWAP', alpha=0.7)\n",
    "\n",
    "# Plot extreme widening events\n",
    "extreme_widening = spread_events[spread_events['extreme_widening'] == 1].index\n",
    "plt.scatter(extreme_widening, squid_vwap.loc[extreme_widening], \n",
    "            marker='^', s=100, color='red', label='Extreme Widening')\n",
    "\n",
    "# Plot extreme narrowing events\n",
    "extreme_narrowing = spread_events[spread_events['extreme_narrowing'] == 1].index\n",
    "plt.scatter(extreme_narrowing, squid_vwap.loc[extreme_narrowing], \n",
    "            marker='v', s=100, color='green', label='Extreme Narrowing')\n",
    "\n",
    "plt.title('Squid_Ink VWAP with Spread Events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot spread\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(spread_events['spread'], label='Spread', alpha=0.7)\n",
    "\n",
    "# Plot extreme widening events\n",
    "plt.scatter(extreme_widening, spread_events.loc[extreme_widening, 'spread'], \n",
    "            marker='^', s=100, color='red', label='Extreme Widening')\n",
    "\n",
    "# Plot extreme narrowing events\n",
    "plt.scatter(extreme_narrowing, spread_events.loc[extreme_narrowing, 'spread'], \n",
    "            marker='v', s=100, color='green', label='Extreme Narrowing')\n",
    "\n",
    "plt.title('Spread with Events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Post-Event Returns\n",
    "\n",
    "Let's analyze the returns following spread events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate post-event returns\n",
    "def calculate_post_event_returns(events, returns, event_col, horizons=[1, 5, 10, 20]):\n",
    "    \"\"\"Calculate returns after events for different time horizons.\"\"\"\n",
    "    post_returns = {}\n",
    "    \n",
    "    # Get event timestamps\n",
    "    event_times = events[events[event_col] == 1].index\n",
    "    \n",
    "    if len(event_times) == 0:\n",
    "        return {h: np.nan for h in horizons}\n",
    "    \n",
    "    # Calculate post-event returns for each horizon\n",
    "    for horizon in horizons:\n",
    "        horizon_returns = []\n",
    "        \n",
    "        for time in event_times:\n",
    "            try:\n",
    "                # Get the index position\n",
    "                idx = returns.index.get_loc(time)\n",
    "                \n",
    "                # Calculate cumulative return for the horizon\n",
    "                if idx + horizon < len(returns):\n",
    "                    cum_ret = returns.iloc[idx+1:idx+horizon+1].sum()\n",
    "                    horizon_returns.append(cum_ret)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if horizon_returns:\n",
    "            post_returns[horizon] = np.mean(horizon_returns)\n",
    "        else:\n",
    "            post_returns[horizon] = np.nan\n",
    "    \n",
    "    return post_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate post-event returns for different spread events\n",
    "horizons = [1, 5, 10, 20, 50]\n",
    "post_returns = {}\n",
    "\n",
    "for col in spread_events.columns:\n",
    "    if col.endswith('_widening') or col.endswith('_narrowing'):\n",
    "        post_returns[col] = calculate_post_event_returns(spread_events, log_ret, col, horizons)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "post_returns_df = pd.DataFrame(post_returns)\n",
    "\n",
    "# Display the results\n",
    "post_returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize post-event returns\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot post-event returns for widening events\n",
    "plt.subplot(2, 1, 1)\n",
    "for col in [c for c in post_returns_df.columns if 'widening' in c]:\n",
    "    plt.plot(post_returns_df.index, post_returns_df[col], marker='o', label=col)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Post-Event Returns for Spread Widening Events')\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Average Return')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot post-event returns for narrowing events\n",
    "plt.subplot(2, 1, 2)\n",
    "for col in [c for c in post_returns_df.columns if 'narrowing' in c]:\n",
    "    plt.plot(post_returns_df.index, post_returns_df[col], marker='o', label=col)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.title('Post-Event Returns for Spread Narrowing Events')\n",
    "plt.xlabel('Time Horizon')\n",
    "plt.ylabel('Average Return')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Develop a Trading Strategy\n",
    "\n",
    "Based on our analysis of spread events, let's develop a simple trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple trading strategy based on spread events\n",
    "def spread_trading_strategy(prices, log_ret, spread_events, event_type, horizon):\n",
    "    \"\"\"Implement a simple trading strategy based on spread events.\n",
    "    \n",
    "    Parameters:\n",
    "    - prices: DataFrame with price data\n",
    "    - log_ret: Series with log returns\n",
    "    - spread_events: DataFrame with spread events\n",
    "    - event_type: Type of event to trade (e.g., 'extreme_widening')\n",
    "    - horizon: Holding period after event\n",
    "    \n",
    "    Returns:\n",
    "    - positions: Series with trading positions (1 for long, -1 for short, 0 for no position)\n",
    "    - returns: Series with strategy returns\n",
    "    \"\"\"\n",
    "    # Initialize positions\n",
    "    positions = pd.Series(0, index=prices.index)\n",
    "    \n",
    "    # Get event timestamps\n",
    "    event_times = spread_events[spread_events[event_type] == 1].index\n",
    "    \n",
    "    # Set positions based on events\n",
    "    for time in event_times:\n",
    "        try:\n",
    "            # Get the index position\n",
    "            idx = prices.index.get_loc(time)\n",
    "            \n",
    "            # Set position based on event type\n",
    "            if 'widening' in event_type:\n",
    "                # For widening spread, go short (market makers are pulling liquidity)\n",
    "                pos = -1\n",
    "            elif 'narrowing' in event_type:\n",
    "                # For narrowing spread, go long (market makers are adding liquidity)\n",
    "                pos = 1\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Set position for the holding period\n",
    "            end_idx = min(idx + horizon + 1, len(positions))\n",
    "            positions.iloc[idx+1:end_idx] = pos\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event at {time}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    # Shift positions by 1 to avoid look-ahead bias\n",
    "    strategy_returns = positions.shift(1) * log_ret\n",
    "    \n",
    "    return positions, strategy_returns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the strategy with different parameters\n",
    "strategy_results = {}\n",
    "\n",
    "# Test different event types and horizons\n",
    "for event_type in ['moderate_widening', 'moderate_narrowing', \n",
    "                   'strong_widening', 'strong_narrowing',\n",
    "                   'extreme_widening', 'extreme_narrowing']:\n",
    "    for horizon in [5, 10, 20]:\n",
    "        strategy_name = f\"{event_type}_h{horizon}\"\n",
    "        \n",
    "        # Run the strategy\n",
    "        positions, returns = spread_trading_strategy(\n",
    "            in_sample_prices, log_ret, spread_events, event_type, horizon)\n",
    "        \n",
    "        # Calculate performance metrics\n",
    "        total_return = returns.sum()\n",
    "        sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252)  # Annualized\n",
    "        win_rate = (returns > 0).mean()\n",
    "        \n",
    "        # Store results\n",
    "        strategy_results[strategy_name] = {\n",
    "            'Total Return': total_return,\n",
    "            'Sharpe Ratio': sharpe_ratio,\n",
    "            'Win Rate': win_rate,\n",
    "            'Returns': returns\n",
    "        }\n",
    "\n",
    "# Display performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'Total Return': results['Total Return'],\n",
    "        'Sharpe Ratio': results['Sharpe Ratio'],\n",
    "        'Win Rate': results['Win Rate']\n",
    "    } for name, results in strategy_results.items()\n",
    "}).T\n",
    "\n",
    "metrics_df.sort_values('Sharpe Ratio', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns for the best strategies\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Sort strategies by Sharpe ratio\n",
    "top_strategies = metrics_df.sort_values('Sharpe Ratio', ascending=False).head(3).index\n",
    "\n",
    "for strategy_name in top_strategies:\n",
    "    returns = strategy_results[strategy_name]['Returns']\n",
    "    plt.plot(returns.cumsum(), label=strategy_name)\n",
    "\n",
    "plt.title('Cumulative Returns of Top Spread Strategies')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've analyzed bid-ask spread events in the Squid_Ink data and developed trading strategies based on these events. We've used only the first 20,000 timestamps (in-sample data) for our analysis.\n",
    "\n",
    "Key findings:\n",
    "1. Spread events (widening and narrowing) occur with varying frequencies and magnitudes\n",
    "2. There are patterns in post-event returns that can be exploited for trading\n",
    "3. The best strategy appears to be [to be filled after running]\n",
    "\n",
    "In future analyses, we could explore combining spread events with price spike events and volume imbalance events to develop more robust trading strategies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
