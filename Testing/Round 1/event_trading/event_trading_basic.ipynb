{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event-Based Trading Analysis\n",
    "\n",
    "This notebook focuses on analyzing event-based trading strategies for Squid_Ink. We'll use only the first 20,000 timestamps (in-sample data) for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Import our backtester package\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from backtester import get_price_data, get_vwap, relative_entropy_binned\n",
    "print(\"Using backtester package\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "First, let's load the Squid_Ink price data and limit it to the first 20,000 timestamps (in-sample data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data directly using backtester package\n",
    "print(\"Loading price data...\")\n",
    "prices = get_price_data('SQUID_INK', 1)\n",
    "print(f\"Loaded {len(prices)} price data points\")\n",
    "\n",
    "# Limit to first 20,000 timestamps (in-sample data)\n",
    "in_sample_prices = prices.iloc[:20000]\n",
    "print(f\"Limited to {len(in_sample_prices)} in-sample data points\")\n",
    "\n",
    "# Get VWAP\n",
    "print(\"Getting VWAP for SQUID_INK...\")\n",
    "squid_vwap = in_sample_prices['vwap']\n",
    "print(f\"Got VWAP with {len(squid_vwap)} data points\")\n",
    "print(f\"VWAP range: {squid_vwap.min()} to {squid_vwap.max()}\")\n",
    "\n",
    "# Calculate log returns\n",
    "log_ret = np.log(squid_vwap).diff().dropna()\n",
    "print(f\"Calculated log returns with {len(log_ret)} data points\")\n",
    "\n",
    "# Plot VWAP\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(squid_vwap)\n",
    "plt.title('Squid_Ink VWAP (In-Sample Data)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calculate Order Book Features\n",
    "\n",
    "Let's calculate some order book features that might be useful for event-based trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate bid-ask spread\n",
    "in_sample_prices['spread'] = in_sample_prices['ask_price_1'] - in_sample_prices['bid_price_1']\n",
    "\n",
    "# Calculate mid price\n",
    "in_sample_prices['mid_price_calc'] = (in_sample_prices['ask_price_1'] + in_sample_prices['bid_price_1']) / 2\n",
    "\n",
    "# Calculate order book imbalance\n",
    "in_sample_prices['bid_volume_total'] = in_sample_prices['bid_volume_1'] + in_sample_prices['bid_volume_2'].fillna(0) + in_sample_prices['bid_volume_3'].fillna(0)\n",
    "in_sample_prices['ask_volume_total'] = in_sample_prices['ask_volume_1'] + in_sample_prices['ask_volume_2'].fillna(0) + in_sample_prices['ask_volume_3'].fillna(0)\n",
    "in_sample_prices['volume_imbalance'] = (in_sample_prices['bid_volume_total'] - in_sample_prices['ask_volume_total']) / (in_sample_prices['bid_volume_total'] + in_sample_prices['ask_volume_total'])\n",
    "\n",
    "# Display the first few rows with the new features\n",
    "in_sample_prices[['spread', 'mid_price_calc', 'bid_volume_total', 'ask_volume_total', 'volume_imbalance']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Price Spike Events\n",
    "\n",
    "Let's define price spike events based on the magnitude of log returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of log returns\n",
    "log_ret_std = log_ret.std()\n",
    "print(f\"Log returns standard deviation: {log_ret_std:.6f}\")\n",
    "\n",
    "# Define price spike thresholds\n",
    "spike_thresholds = {\n",
    "    'small': 2 * log_ret_std,  # 2 standard deviations\n",
    "    'medium': 3 * log_ret_std,  # 3 standard deviations\n",
    "    'large': 4 * log_ret_std    # 4 standard deviations\n",
    "}\n",
    "\n",
    "# Display the thresholds\n",
    "for name, threshold in spike_thresholds.items():\n",
    "    print(f\"{name.capitalize()} spike threshold: {threshold:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify price spike events\n",
    "spike_events = pd.DataFrame(index=log_ret.index)\n",
    "spike_events['log_ret'] = log_ret\n",
    "spike_events['abs_log_ret'] = log_ret.abs()\n",
    "\n",
    "# Classify spikes by magnitude\n",
    "for name, threshold in spike_thresholds.items():\n",
    "    spike_events[f'{name}_spike'] = (spike_events['abs_log_ret'] > threshold).astype(int)\n",
    "    spike_events[f'{name}_spike_up'] = ((log_ret > threshold)).astype(int)\n",
    "    spike_events[f'{name}_spike_down'] = ((log_ret < -threshold)).astype(int)\n",
    "\n",
    "# Display the first few rows\n",
    "spike_events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze Price Spike Events\n",
    "\n",
    "Let's analyze the frequency and characteristics of price spike events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of spike events by type\n",
    "spike_counts = {\n",
    "    'small': spike_events['small_spike'].sum(),\n",
    "    'small_up': spike_events['small_spike_up'].sum(),\n",
    "    'small_down': spike_events['small_spike_down'].sum(),\n",
    "    'medium': spike_events['medium_spike'].sum(),\n",
    "    'medium_up': spike_events['medium_spike_up'].sum(),\n",
    "    'medium_down': spike_events['medium_spike_down'].sum(),\n",
    "    'large': spike_events['large_spike'].sum(),\n",
    "    'large_up': spike_events['large_spike_up'].sum(),\n",
    "    'large_down': spike_events['large_spike_down'].sum()\n",
    "}\n",
    "\n",
    "# Calculate the percentage of spike events\n",
    "total_points = len(spike_events)\n",
    "spike_percentages = {k: v / total_points * 100 for k, v in spike_counts.items()}\n",
    "\n",
    "# Display the counts and percentages\n",
    "counts_df = pd.DataFrame({\n",
    "    'Count': spike_counts,\n",
    "    'Percentage (%)': spike_percentages\n",
    "})\n",
    "\n",
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Price Spike Events\n",
    "\n",
    "Let's visualize the price spike events on the VWAP chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VWAP with spike events\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot VWAP\n",
    "plt.plot(squid_vwap, label='VWAP', alpha=0.7)\n",
    "\n",
    "# Plot spike events\n",
    "for name in ['small', 'medium', 'large']:\n",
    "    # Up spikes\n",
    "    up_spikes = spike_events[spike_events[f'{name}_spike_up'] == 1].index\n",
    "    plt.scatter(up_spikes, squid_vwap.loc[up_spikes], \n",
    "                marker='^', s=100, label=f'{name.capitalize()} Up Spike')\n",
    "    \n",
    "    # Down spikes\n",
    "    down_spikes = spike_events[spike_events[f'{name}_spike_down'] == 1].index\n",
    "    plt.scatter(down_spikes, squid_vwap.loc[down_spikes], \n",
    "                marker='v', s=100, label=f'{name.capitalize()} Down Spike')\n",
    "\n",
    "plt.title('Squid_Ink VWAP with Price Spike Events')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Develop a Simple Trading Strategy\n",
    "\n",
    "Based on our analysis of price spikes, let's develop a simple trading strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple trading strategy based on price spikes\n",
    "def spike_trading_strategy(prices, log_ret, spike_events, spike_type, horizon, direction='reverse'):\n",
    "    \"\"\"Implement a simple trading strategy based on price spikes.\n",
    "    \n",
    "    Parameters:\n",
    "    - prices: DataFrame with price data\n",
    "    - log_ret: Series with log returns\n",
    "    - spike_events: DataFrame with spike events\n",
    "    - spike_type: Type of spike to trade (e.g., 'medium_spike_up')\n",
    "    - horizon: Holding period after spike\n",
    "    - direction: 'reverse' to bet on mean reversion, 'momentum' to bet on trend continuation\n",
    "    \n",
    "    Returns:\n",
    "    - positions: Series with trading positions (1 for long, -1 for short, 0 for no position)\n",
    "    - returns: Series with strategy returns\n",
    "    \"\"\"\n",
    "    # Initialize positions\n",
    "    positions = pd.Series(0, index=prices.index)\n",
    "    \n",
    "    # Get event timestamps\n",
    "    event_times = spike_events[spike_events[spike_type] == 1].index\n",
    "    \n",
    "    # Set positions based on events\n",
    "    for time in event_times:\n",
    "        try:\n",
    "            # Get the index position\n",
    "            idx = prices.index.get_loc(time)\n",
    "            \n",
    "            # Set position based on direction\n",
    "            if direction == 'reverse':\n",
    "                # For mean reversion: go against the spike direction\n",
    "                if spike_type.endswith('_up'):\n",
    "                    pos = -1  # Short after up spike\n",
    "                elif spike_type.endswith('_down'):\n",
    "                    pos = 1   # Long after down spike\n",
    "                else:\n",
    "                    # For general spikes, look at the sign of the return\n",
    "                    ret = log_ret.iloc[idx]\n",
    "                    pos = -1 if ret > 0 else 1\n",
    "            else:  # momentum\n",
    "                # For momentum: go with the spike direction\n",
    "                if spike_type.endswith('_up'):\n",
    "                    pos = 1   # Long after up spike\n",
    "                elif spike_type.endswith('_down'):\n",
    "                    pos = -1  # Short after down spike\n",
    "                else:\n",
    "                    # For general spikes, look at the sign of the return\n",
    "                    ret = log_ret.iloc[idx]\n",
    "                    pos = 1 if ret > 0 else -1\n",
    "            \n",
    "            # Set position for the holding period\n",
    "            end_idx = min(idx + horizon + 1, len(positions))\n",
    "            positions.iloc[idx+1:end_idx] = pos\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing event at {time}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    # Shift positions by 1 to avoid look-ahead bias\n",
    "    strategy_returns = positions.shift(1) * log_ret\n",
    "    \n",
    "    return positions, strategy_returns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the strategy with different parameters\n",
    "strategy_results = {}\n",
    "\n",
    "# Test different spike types and horizons\n",
    "for spike_type in ['medium_spike_up', 'medium_spike_down']:\n",
    "    for horizon in [5, 10, 20]:\n",
    "        for direction in ['reverse', 'momentum']:\n",
    "            strategy_name = f\"{spike_type}_{direction}_h{horizon}\"\n",
    "            \n",
    "            # Run the strategy\n",
    "            positions, returns = spike_trading_strategy(\n",
    "                in_sample_prices, log_ret, spike_events, spike_type, horizon, direction)\n",
    "            \n",
    "            # Calculate performance metrics\n",
    "            total_return = returns.sum()\n",
    "            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252)  # Annualized\n",
    "            win_rate = (returns > 0).mean()\n",
    "            \n",
    "            # Store results\n",
    "            strategy_results[strategy_name] = {\n",
    "                'Total Return': total_return,\n",
    "                'Sharpe Ratio': sharpe_ratio,\n",
    "                'Win Rate': win_rate,\n",
    "                'Returns': returns\n",
    "            }\n",
    "\n",
    "# Display performance metrics\n",
    "metrics_df = pd.DataFrame({\n",
    "    name: {\n",
    "        'Total Return': results['Total Return'],\n",
    "        'Sharpe Ratio': results['Sharpe Ratio'],\n",
    "        'Win Rate': results['Win Rate']\n",
    "    } for name, results in strategy_results.items()\n",
    "}).T\n",
    "\n",
    "metrics_df.sort_values('Sharpe Ratio', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns for the best strategies\n",
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "# Sort strategies by Sharpe ratio\n",
    "top_strategies = metrics_df.sort_values('Sharpe Ratio', ascending=False).head(3).index\n",
    "\n",
    "for strategy_name in top_strategies:\n",
    "    returns = strategy_results[strategy_name]['Returns']\n",
    "    plt.plot(returns.cumsum(), label=strategy_name)\n",
    "\n",
    "plt.title('Cumulative Returns of Top Price Spike Strategies')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we've analyzed event-based trading strategies for Squid_Ink using only the first 20,000 timestamps (in-sample data). We've focused on price spike events and developed trading strategies based on these events.\n",
    "\n",
    "Key findings:\n",
    "1. Price spikes occur with varying frequencies and magnitudes\n",
    "2. There are patterns in post-spike behavior that can be exploited for trading\n",
    "3. The best strategy appears to be [to be filled after running]\n",
    "\n",
    "In future analyses, we could explore other types of events such as volume imbalance events, spread widening events, or order book pressure events."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
