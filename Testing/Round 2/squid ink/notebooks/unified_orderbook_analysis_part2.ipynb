{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Orderbooks Before Large Returns - Squid Ink Round 2 (Part 2)\n",
    "\n",
    "This notebook continues the analysis of orderbooks before large returns for Squid Ink in Round 2.\n",
    "\n",
    "## Part 2: Extract Orderbook Features\n",
    "\n",
    "In this part, we'll extract and analyze orderbook features right before large return events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configure plots to be larger and more readable\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Try to import seaborn for better styling\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    print(\"Using Seaborn for plot styling\")\n",
    "except ImportError:\n",
    "    print(\"Seaborn not available, using matplotlib default styling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load Data from Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data directory path\n",
    "data_dir = '../data'\n",
    "\n",
    "# Load processed data from Part 1\n",
    "try:\n",
    "    squid_data = pd.read_pickle(os.path.join(data_dir, 'squid_data_with_returns.pkl'))\n",
    "    large_return_indices = pd.read_pickle(os.path.join(data_dir, 'large_return_indices.pkl')).values\n",
    "    print(f\"Successfully loaded data from Part 1\")\n",
    "    print(f\"Number of rows in squid_data: {len(squid_data)}\")\n",
    "    print(f\"Number of large return events: {len(large_return_indices)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find data files from Part 1.\")\n",
    "    print(\"Please run Part 1 first to generate the necessary data files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define Function to Calculate Orderbook Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def calculate_orderbook_features(data):\n",
    "    \"\"\"\n",
    "    Calculate various orderbook features.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): DataFrame containing orderbook data\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with orderbook features\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Calculate bid-ask spread\n",
    "    df['spread'] = df['ask_price_1'] - df['bid_price_1']\n",
    "    df['relative_spread'] = df['spread'] / df['mid_price']\n",
    "    \n",
    "    # Calculate total volume at each level\n",
    "    df['bid_volume_total'] = df['bid_volume_1'] + df['bid_volume_2'].fillna(0) + df['bid_volume_3'].fillna(0)\n",
    "    df['ask_volume_total'] = df['ask_volume_1'] + df['ask_volume_2'].fillna(0) + df['ask_volume_3'].fillna(0)\n",
    "    \n",
    "    # Calculate volume imbalance\n",
    "    df['volume_imbalance'] = (df['bid_volume_total'] - df['ask_volume_total']) / (df['bid_volume_total'] + df['ask_volume_total'])\n",
    "    \n",
    "    # Calculate weighted average price levels\n",
    "    df['weighted_bid_price'] = (\n",
    "        df['bid_price_1'] * df['bid_volume_1'] + \n",
    "        df['bid_price_2'].fillna(0) * df['bid_volume_2'].fillna(0) + \n",
    "        df['bid_price_3'].fillna(0) * df['bid_volume_3'].fillna(0)\n",
    "    ) / df['bid_volume_total']\n",
    "    \n",
    "    df['weighted_ask_price'] = (\n",
    "        df['ask_price_1'] * df['ask_volume_1'] + \n",
    "        df['ask_price_2'].fillna(0) * df['ask_volume_2'].fillna(0) + \n",
    "        df['ask_price_3'].fillna(0) * df['ask_volume_3'].fillna(0)\n",
    "    ) / df['ask_volume_total']\n",
    "    \n",
    "    # Calculate price impact - how much the price would move if a large order came in\n",
    "    # (simplified version - assumes linear price impact)\n",
    "    df['bid_price_impact'] = (df['bid_price_1'] - df['bid_price_3'].fillna(df['bid_price_1'])) / df['bid_price_1']\n",
    "    df['ask_price_impact'] = (df['ask_price_3'].fillna(df['ask_price_1']) - df['ask_price_1']) / df['ask_price_1']\n",
    "    \n",
    "    # Calculate order book depth (total volume within first 3 levels)\n",
    "    df['book_depth'] = df['bid_volume_total'] + df['ask_volume_total']\n",
    "    \n",
    "    # Calculate price range (difference between highest ask and lowest bid)\n",
    "    df['price_range'] = df['ask_price_3'].fillna(df['ask_price_1']) - df['bid_price_3'].fillna(df['bid_price_1'])\n",
    "    df['relative_price_range'] = df['price_range'] / df['mid_price']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Calculate Orderbook Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate orderbook features for the entire dataset\n",
    "squid_data_with_features = calculate_orderbook_features(squid_data)\n",
    "\n",
    "# Display the first few rows with the new features\n",
    "feature_columns = [\n",
    "    'timestamp', 'mid_price', 'returns', 'abs_returns',\n",
    "    'spread', 'relative_spread', 'volume_imbalance',\n",
    "    'bid_volume_total', 'ask_volume_total', 'book_depth',\n",
    "    'weighted_bid_price', 'weighted_ask_price',\n",
    "    'bid_price_impact', 'ask_price_impact',\n",
    "    'price_range', 'relative_price_range'\n",
    "]\n",
    "\n",
    "squid_data_with_features[feature_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Extract Orderbook States Before Large Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extract orderbook states before large returns\n",
    "# We'll look at the orderbook 1 step before the large return event\n",
    "\n",
    "# Create a dictionary to store pre-event orderbook states\n",
    "pre_event_states = {}\n",
    "\n",
    "for idx in large_return_indices:\n",
    "    if idx > 0:  # Make sure we're not at the first observation\n",
    "        # Get the timestamp of the large return event\n",
    "        event_timestamp = squid_data.loc[idx, 'timestamp']\n",
    "        \n",
    "        # Get the return value\n",
    "        return_value = squid_data.loc[idx, 'returns']\n",
    "        \n",
    "        # Get the orderbook state 1 step before the event\n",
    "        pre_event_idx = idx - 1\n",
    "        pre_event_state = squid_data_with_features.loc[pre_event_idx]\n",
    "        \n",
    "        # Store in dictionary with event timestamp as key\n",
    "        pre_event_states[event_timestamp] = {\n",
    "            'pre_event_state': pre_event_state,\n",
    "            'return_value': return_value\n",
    "        }\n",
    "\n",
    "print(f\"Extracted {len(pre_event_states)} pre-event orderbook states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Create DataFrame of Pre-Event Orderbook States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convert pre-event states to a DataFrame for easier analysis\n",
    "pre_event_df = pd.DataFrame({\n",
    "    'timestamp': [ts for ts in pre_event_states.keys()],\n",
    "    'return_value': [data['return_value'] for data in pre_event_states.values()],\n",
    "    'spread': [data['pre_event_state']['spread'] for data in pre_event_states.values()],\n",
    "    'relative_spread': [data['pre_event_state']['relative_spread'] for data in pre_event_states.values()],\n",
    "    'volume_imbalance': [data['pre_event_state']['volume_imbalance'] for data in pre_event_states.values()],\n",
    "    'bid_volume_total': [data['pre_event_state']['bid_volume_total'] for data in pre_event_states.values()],\n",
    "    'ask_volume_total': [data['pre_event_state']['ask_volume_total'] for data in pre_event_states.values()],\n",
    "    'book_depth': [data['pre_event_state']['book_depth'] for data in pre_event_states.values()],\n",
    "    'bid_price_impact': [data['pre_event_state']['bid_price_impact'] for data in pre_event_states.values()],\n",
    "    'ask_price_impact': [data['pre_event_state']['ask_price_impact'] for data in pre_event_states.values()],\n",
    "    'price_range': [data['pre_event_state']['price_range'] for data in pre_event_states.values()],\n",
    "    'relative_price_range': [data['pre_event_state']['relative_price_range'] for data in pre_event_states.values()]\n",
    "})\n",
    "\n",
    "# Add a column for return direction (positive or negative)\n",
    "pre_event_df['return_direction'] = np.where(pre_event_df['return_value'] > 0, 'positive', 'negative')\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Summary of pre-event orderbook states:\")\n",
    "pre_event_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Visualize Distribution of Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the distribution of key features\n",
    "key_features = ['spread', 'relative_spread', 'volume_imbalance', 'book_depth', 'bid_price_impact', 'ask_price_impact']\n",
    "\n",
    "for feature in key_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(pre_event_df[feature].dropna(), bins=30, alpha=0.7)\n",
    "    plt.title(f'Distribution of {feature} Before Large Return Events')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Save Data for Next Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the data for the next part\n",
    "squid_data_with_features.to_pickle(os.path.join(data_dir, 'squid_data_with_features.pkl'))\n",
    "print(f\"Saved data with features to {os.path.join(data_dir, 'squid_data_with_features.pkl')}\")\n",
    "\n",
    "pre_event_df.to_pickle(os.path.join(data_dir, 'pre_event_orderbook_states.pkl'))\n",
    "print(f\"Saved pre-event orderbook states to {os.path.join(data_dir, 'pre_event_orderbook_states.pkl')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Part 2\n",
    "\n",
    "In this second part of the analysis, we have:\n",
    "\n",
    "1. Loaded the data from Part 1\n",
    "2. Calculated various orderbook features (spread, volume imbalance, etc.)\n",
    "3. Extracted the orderbook state right before large return events\n",
    "4. Created a DataFrame of pre-event orderbook states for analysis\n",
    "5. Visualized the distribution of key features\n",
    "6. Saved the processed data for use in the next part\n",
    "\n",
    "In Part 3, we will analyze the relationship between these orderbook features and subsequent returns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
