{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Orderbooks Before Large Returns - Squid Ink Round 2 (Part 3)\n",
    "\n",
    "This notebook continues the analysis of orderbooks before large returns for Squid Ink in Round 2.\n",
    "\n",
    "## Part 3: Analyze Relationship Between Orderbook Features and Returns\n",
    "\n",
    "In this part, we'll analyze the relationship between orderbook features and subsequent returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Configure plots to be larger and more readable\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Try to import seaborn for better styling\n",
    "try:\n",
    "    import seaborn as sns\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    print(\"Using Seaborn for plot styling\")\n",
    "except ImportError:\n",
    "    print(\"Seaborn not available, using matplotlib default styling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Load Data from Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create data directory path\n",
    "data_dir = '../data'\n",
    "\n",
    "# Load processed data from Part 2\n",
    "try:\n",
    "    squid_data_with_features = pd.read_pickle(os.path.join(data_dir, 'squid_data_with_features.pkl'))\n",
    "    pre_event_df = pd.read_pickle(os.path.join(data_dir, 'pre_event_orderbook_states.pkl'))\n",
    "    print(f\"Successfully loaded data from Part 2\")\n",
    "    print(f\"Number of rows in squid_data_with_features: {len(squid_data_with_features)}\")\n",
    "    print(f\"Number of pre-event orderbook states: {len(pre_event_df)}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Could not find data files from Part 2.\")\n",
    "    print(\"Please run Part 2 first to generate the necessary data files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Separate Positive and Negative Return Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Separate positive and negative return events\n",
    "positive_returns = pre_event_df[pre_event_df['return_direction'] == 'positive']\n",
    "negative_returns = pre_event_df[pre_event_df['return_direction'] == 'negative']\n",
    "\n",
    "print(f\"Number of large positive return events: {len(positive_returns)}\")\n",
    "print(f\"Number of large negative return events: {len(negative_returns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Compare Orderbook Features Between Positive and Negative Return Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare orderbook features between positive and negative return events\n",
    "feature_comparison = pd.DataFrame({\n",
    "    'positive_mean': positive_returns.mean(),\n",
    "    'negative_mean': negative_returns.mean(),\n",
    "    'positive_median': positive_returns.median(),\n",
    "    'negative_median': negative_returns.median()\n",
    "})\n",
    "\n",
    "# Calculate the difference between positive and negative events\n",
    "feature_comparison['mean_diff'] = feature_comparison['positive_mean'] - feature_comparison['negative_mean']\n",
    "feature_comparison['median_diff'] = feature_comparison['positive_median'] - feature_comparison['negative_median']\n",
    "\n",
    "# Calculate the percentage difference\n",
    "feature_comparison['mean_diff_pct'] = feature_comparison['mean_diff'] / feature_comparison['negative_mean'] * 100\n",
    "feature_comparison['median_diff_pct'] = feature_comparison['median_diff'] / feature_comparison['negative_median'] * 100\n",
    "\n",
    "# Display the comparison for relevant features\n",
    "relevant_features = [\n",
    "    'spread', 'relative_spread', 'volume_imbalance',\n",
    "    'bid_volume_total', 'ask_volume_total', 'book_depth',\n",
    "    'bid_price_impact', 'ask_price_impact',\n",
    "    'price_range', 'relative_price_range'\n",
    "]\n",
    "\n",
    "feature_comparison.loc[relevant_features, ['mean_diff_pct', 'median_diff_pct']].sort_values('mean_diff_pct', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Visualize Distribution of Key Features for Positive vs Negative Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize the distribution of key features for positive vs negative returns\n",
    "key_features = [\n",
    "    'volume_imbalance', 'relative_spread', 'book_depth', 'bid_price_impact', 'ask_price_impact'\n",
    "]\n",
    "\n",
    "for feature in key_features:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.hist(positive_returns[feature].dropna(), bins=20, alpha=0.5, label='Positive Returns')\n",
    "    plt.hist(negative_returns[feature].dropna(), bins=20, alpha=0.5, label='Negative Returns')\n",
    "    \n",
    "    plt.title(f'Distribution of {feature} Before Large Return Events')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Calculate Correlation Between Orderbook Features and Return Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate correlation between orderbook features and return values\n",
    "correlation = pre_event_df[relevant_features + ['return_value']].corr()['return_value'].drop('return_value')\n",
    "\n",
    "# Sort by absolute correlation\n",
    "correlation_sorted = correlation.abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the correlations\n",
    "print(\"Correlation between orderbook features and subsequent returns:\")\n",
    "for feature in correlation_sorted.index:\n",
    "    print(f\"{feature}: {correlation[feature]:.4f}\")\n",
    "\n",
    "# Plot the correlations\n",
    "plt.figure(figsize=(12, 8))\n",
    "correlation.sort_values().plot(kind='barh')\n",
    "plt.title('Correlation Between Orderbook Features and Subsequent Returns')\n",
    "plt.xlabel('Correlation')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Create Scatter Plots of Most Correlated Features vs Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Scatter plots of the most correlated features vs returns\n",
    "top_features = correlation_sorted.index[:3]  # Top 3 most correlated features\n",
    "\n",
    "for feature in top_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(pre_event_df[feature], pre_event_df['return_value'], alpha=0.6)\n",
    "    plt.title(f'Relationship Between {feature} and Subsequent Returns')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Return Value')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Perform Statistical Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Perform t-tests for each feature\n",
    "t_test_results = {}\n",
    "\n",
    "for feature in relevant_features:\n",
    "    # Get the data for positive and negative returns\n",
    "    pos_data = positive_returns[feature].dropna()\n",
    "    neg_data = negative_returns[feature].dropna()\n",
    "    \n",
    "    # Perform t-test\n",
    "    t_stat, p_value = stats.ttest_ind(pos_data, neg_data, equal_var=False)\n",
    "    \n",
    "    # Store results\n",
    "    t_test_results[feature] = {\n",
    "        't_statistic': t_stat,\n",
    "        'p_value': p_value,\n",
    "        'significant': p_value < 0.05\n",
    "    }\n",
    "\n",
    "# Convert to DataFrame for easier viewing\n",
    "t_test_df = pd.DataFrame(t_test_results).T\n",
    "t_test_df = t_test_df.sort_values('p_value')\n",
    "\n",
    "# Display results\n",
    "print(\"T-test results for orderbook features (positive vs negative returns):\")\n",
    "t_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Determine Feature Importance Using Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import machine learning libraries\n",
    "try:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score, classification_report\n",
    "    print(\"Successfully imported scikit-learn libraries\")\n",
    "except ImportError:\n",
    "    print(\"Warning: scikit-learn not available. Skipping machine learning analysis.\")\n",
    "    has_sklearn = False\n",
    "else:\n",
    "    has_sklearn = True\n",
    "\n",
    "if has_sklearn:\n",
    "    # Prepare the data\n",
    "    X = pre_event_df[relevant_features].copy()\n",
    "    y = (pre_event_df['return_value'] > 0).astype(int)  # 1 for positive returns, 0 for negative\n",
    "\n",
    "    # Handle missing values\n",
    "    X = X.fillna(X.mean())\n",
    "\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train a random forest classifier\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Model accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Get feature importances\n",
    "    feature_importances = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': rf.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Plot feature importances\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.barh(feature_importances['feature'], feature_importances['importance'])\n",
    "    plt.title('Feature Importance for Predicting Return Direction')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Save Data for Next Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the data for the next part\n",
    "positive_returns.to_pickle(os.path.join(data_dir, 'positive_return_events.pkl'))\n",
    "print(f\"Saved positive return events to {os.path.join(data_dir, 'positive_return_events.pkl')}\")\n",
    "\n",
    "negative_returns.to_pickle(os.path.join(data_dir, 'negative_return_events.pkl'))\n",
    "print(f\"Saved negative return events to {os.path.join(data_dir, 'negative_return_events.pkl')}\")\n",
    "\n",
    "if has_sklearn:\n",
    "    feature_importances.to_pickle(os.path.join(data_dir, 'feature_importances.pkl'))\n",
    "    print(f\"Saved feature importances to {os.path.join(data_dir, 'feature_importances.pkl')}\")\n",
    "\n",
    "pd.DataFrame(t_test_results).T.to_pickle(os.path.join(data_dir, 't_test_results.pkl'))\n",
    "print(f\"Saved t-test results to {os.path.join(data_dir, 't_test_results.pkl')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Part 3\n",
    "\n",
    "In this third part of the analysis, we have:\n",
    "\n",
    "1. Loaded the data from Part 2\n",
    "2. Separated positive and negative return events\n",
    "3. Compared orderbook features between positive and negative returns\n",
    "4. Visualized the distribution of key features\n",
    "5. Calculated correlations between features and returns\n",
    "6. Performed statistical tests to identify significant differences\n",
    "7. Used machine learning to determine feature importance\n",
    "8. Saved the processed data for use in the next part\n",
    "\n",
    "In Part 4, we will visualize orderbook patterns before large return events."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
